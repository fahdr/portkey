kube-prometheus-stack:
  # k3s bundles these components into its binary - they don't expose separate metrics
  kubeControllerManager:
    enabled: false
  kubeProxy:
    enabled: false
  kubeScheduler:
    enabled: false
  # TODO: Re-enable KubeHpaMaxedOut once WordPress PVCs use RWX storage (CephFS/NFS)
  # so HPAs can scale beyond 1 replica. Currently maxReplicas=1 due to RWO PVC constraint,
  # which causes false-positive KubeHpaMaxedOut alerts.
  defaultRules:
    disabled:
      KubeHpaMaxedOut: true
  grafana:
    enabled: false
    forceDeployDatasources: true
    forceDeployDashboards: true
    additionalDataSources:
      - name: Loki
        type: loki
        url: http://loki.loki:3100
  prometheus:
    prometheusSpec:
      ruleSelectorNilUsesHelmValues: false
      serviceMonitorSelectorNilUsesHelmValues: false
      podMonitorSelectorNilUsesHelmValues: false
      probeSelectorNilUsesHelmValues: false
  alertmanager:
    alertmanagerSpec:
      containers:
        - name: ntfy-relay
          image: ghcr.io/khuedoan/webhook-transformer:v0.0.3
          args:
            - --port=8081
            - --config=/config/alertmanager-to-ntfy.jsonnet
            - --upstream-host=https://ntfy.sh
          envFrom:
            - secretRef:
                name: webhook-transformer
          volumeMounts:
            - name: config
              mountPath: /config
      volumes:
        - name: config
          configMap:
            name: webhook-transformer
    config:
      route:
        receiver: ntfy
        group_by:
          - namespace
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 12h
        routes:
          - receiver: ntfy
            matchers:
              - alertname = "Watchdog"
      receivers:
        - name: ntfy
          webhook_configs:
            - url: http://localhost:8081
              send_resolved: true

# Infrastructure Monitoring Configuration
infrastructure:
  # Proxmox VE Exporter
  proxmox:
    enabled: true
    imageTag: "3.4.5"
    # Only scrape ONE node - the Proxmox API is cluster-aware and returns
    # metrics for ALL nodes/VMs/containers from any single node.
    # Scraping multiple nodes results in duplicate metrics (6 nodes x 6 = 36).
    targets:
      - "192.168.0.2"    # shire (any node works, they all return cluster data)

  # OPNsense Firewall Exporter (AthennaMind)
  opnsense:
    enabled: true
    imageTag: "latest"
    protocol: "https"
    address: "192.168.0.1"
    insecure: "true"  # Set to false if using valid SSL cert

  # AdGuard Home Exporter (running on OPNsense)
  adguard:
    enabled: true
    imageTag: "latest"
    protocol: "http"
    hostname: "192.168.0.1"
    port: "3000"
    interval: "10s"
    logLimit: "1000"

  # External Ceph Cluster (running on Proxmox)
  # Requires: ceph mgr module enable prometheus (run on any Proxmox node)
  ceph:
    enabled: true
    mgrPort: 9283
    # Ceph mgr nodes - typically runs on 2-3 nodes, add all potential mgr hosts
    mgrTargets:
      - "192.168.0.2"    # shire
      - "192.168.0.202"  # rivendell
      - "192.168.0.102"  # isengard

  # External Node Exporter on Proxmox hosts (CPU temp, case temp, fans, system metrics)
  # Requires: apt install prometheus-node-exporter on each Proxmox node
  nodeExporter:
    enabled: true
    port: 9100
    nodes:
      - name: shire
        ip: "192.168.0.2"
      - name: rivendell
        ip: "192.168.0.202"
      - name: isengard
        ip: "192.168.0.102"
      - name: mirkwood
        ip: "192.168.0.8"
      - name: rohan
        ip: "192.168.0.7"
      - name: gondor
        ip: "192.168.0.6"

# SNMP Exporter for additional OPNsense metrics (CPU, memory, disk, etc.)
  # Requires: os-net-snmp plugin installed and configured on OPNsense
  snmp:
    enabled: false  # Disabled - OPNsense SNMP not configured
    imageTag: "v0.26.0"
    targets:
      - name: "opnsense"
        address: "192.168.0.1"
        module: "if_mib"  # Standard interface MIB, works with FreeBSD/OPNsense

# Grafana Dashboards
dashboards:
  enabled: true
